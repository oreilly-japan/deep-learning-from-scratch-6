# 'A' ã®å ´åˆ
encoded = 'A'.encode("utf-8")
print(encoded)        # b'A'
print(list(encoded))  # [65]

# 'ã‚' ã®å ´åˆ
encoded = 'ã‚'.encode("utf-8")
print(encoded)        # b'\xe3\x81\x82'
print(list(encoded))  # [227, 129, 130]

ids = [65]
decoded = bytes(ids).decode("utf-8")
print(decoded)   # 'A'


class ByteTokenizer:
    def encode(self, text):
        return list(text.encode("utf-8"))

    def decode(self, ids):
        return bytes(ids).decode("utf-8")


# ä½¿ç”¨ä¾‹
tokenizer = ByteTokenizer()
text = "helloä¸–ç•ŒğŸ˜"

# ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
ids = tokenizer.encode(text)
print(ids)  # [104, 101, 108, 108, 111, 228, 184, 150, 231, 149, 140, 240, 159, 152, 129]

# ãƒ‡ã‚³ãƒ¼ãƒ‰
decoded = tokenizer.decode(ids)
print(decoded)  # helloä¸–ç•ŒğŸ˜