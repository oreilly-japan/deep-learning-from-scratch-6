text = "helloä¸–ç•ŒğŸ˜"
print(list(text))  # ['h', 'e', 'l', 'l', 'o', 'ä¸–', 'ç•Œ', 'ğŸ˜']

print(ord('h'))  # 104
print(ord('ğŸ˜'))  # 128513

print(chr(104))    # 'h'
print(chr(128513)) # 'ğŸ˜'

ids = [ord(w) for w in list(text)]
print(ids)  # [104, 101, 108, 108, 111, 19990, 30028, 128513]

class CharTokenizer:
    def encode(self, text):
        return [ord(char) for char in text]

    def decode(self, ids):
        return ''.join([chr(i) for i in ids])

tokenizer = CharTokenizer()
text = "helloä¸–ç•ŒğŸ˜"

# ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
ids = tokenizer.encode(text)
print(ids)  # [104, 101, 108, 108, 111, 19990, 30028, 128513]

# ãƒ‡ã‚³ãƒ¼ãƒ‰
decoded = tokenizer.decode(ids)
print(decoded)  # helloä¸–ç•ŒğŸ˜